---
title: "Spam"
author: "willandru"
date: "`r Sys.Date()`"
output: html_document
---
# REGRESIÓN LOGÍSTICA 



## Clasificador de E-mails Spam o No spam

Un conjunto de datos que clasifica 4601 correos electrónicos como spam o no spam. Además de esta etiqueta de clase, existen 57 variables que indican la frecuencia de ciertas palabras y caracteres en el correo electrónico.

Las primeras 48 variables contienen la frecuencia del nombre de la variable en el correo electrónico. Si el nombre de la variable comienza con num (p. ej., num650), indica la frecuencia del número correspondiente (p. ej., 650). Las variables 49-54 indican la frecuencia de los caracteres ';', '(', '[', '!', '$' y '#'. Las variables 55-57 contienen la ejecución promedio, más larga y total. longitud de las letras mayúsculas La variable 58 indica el tipo de correo y es "no spam" o "spam", es decir, correo electrónico comercial no solicitado.


### Libreria 'kernlab' para obtener el dataset
```{r }
library(kernlab)
```

### EDA

Obtenemos el dataset:

```{r }
data(spam)
```

Observemos el nombre de las columnas: 

```{r }
names(spam)
```

Veamos los datos de las primeras filas:

```{r }
head(spam)
```

La estructura del dataset:

```{r }
str(spam)
```

Hechamos un vistaso a la variable de interes:

```{r }
table(spam$type)
```

### MODELO REGRESIÓN LOGÍSTICA: E-MAIL SPAM

#### Preparamos los datos

```{r }
spam$type <- ifelse(spam$type== "spam", 1, 0)
```

```{r }
table(spam$type)
```


#### Creamos conjunto de Entrenamiento y de Prueba

```{r }
set.seed(111)
split <- sort(sample(nrow(spam), nrow(spam)*0.7))
training <- spam[split,]
testing <- spam[-split,]
```

#### Importamos librerias para realizar stepAIC() y buscar el mejor modelo

```{r }
library(dplyr)
library(MASS)

```

#### MODELO BASE

```{r }

base.model = glm(type ~ . , data=spam)
```

#### MEJOR MODELO AIC

```{r }

model = glm(type ~ . , data=spam) %>% stepAIC(trace =TRUE)
```

Comparamos el AIC para ambos modelos:

```{r }
base.model$aic
model$aic
```

Vemos un resumen del mejor modelo:

```{r }
summary(model)

```










```{r }
probabilities <- predict(model, 
                       newdata = testing,
                       type = "response")

predictions <- ifelse(probabilities > 0.5, "1", "0")

trn_tab <- table(predictions, testing$type)

```


#### Ipportamos libreria 'caret' para para obtener las metricas del modelo

```{r }

library("caret")
confusionMatrix(trn_tab, positive = "1")
```

#### Razon de Probabilidad

```{r }

exp(cbind(OR = coef(model), confint(model)))
```




# MNIST: Imagenes de números escritos a mano.


```{r}
N=4000

read.training = file("train-images.idx3-ubyte", "rb")
readBin(read.training,'integer',n=1,size=4,endian='big')
nrow = readBin(read.training,'integer',n=1,size=4,endian='big')
ncol = readBin(read.training,'integer',n=1,size=4,endian='big')
x = data.frame()
for(i in 1:N){m = readBin(read.training,'integer',n=28*28,size=1,signed=F);
    x <- rbind(x, m)}
     close(read.training)
     
     
read.labels = file("train-labels.idx1-ubyte", "rb")
readBin(read.labels,'integer',n=1,size=4,endian='big')
n = readBin(read.labels,'integer',n=1,size=4,endian='big')
y = readBin(read.labels,'integer',n=n,size=1,signed=F)
close(read.labels)
y=data.frame(sapply(as.numeric(y[1:N]), c))

df =x
df['Y'] <- y

```

```{r}
head(df)
```

```{r}
DF=df[(df$Y==0) | (df$Y==1),]

```

```{r}
set.seed(111)
split <- sort(sample(nrow(DF), nrow(DF)*0.7))
training <- DF[split,]
testing <- DF[-split,]
```

```{r}
log_model <- glm(as.factor(Y) ~ .-Y,
                 family = binomial,
                 data = training)
summary(log_model)
```

```{r}
probabilities <- predict(log_model, 
                       newdata = testing,
                       type = "response")
predictions <- ifelse(probabilities > 0.5, "1", "0")
trn_tab <- table(predictions, testing$Y)
```

```{r }

library("caret")
confusionMatrix(trn_tab, positive = "1")
```


# IRIS

```{r }
str(iris)
```


```{r }
library(stats4) #Load package stats
library(splines) #Load package splines
#To load package VGAM, need to load package stats4 and splines.
library(VGAM) 

```

```{r }


fit.MLR <- vglm( Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, family=multinomial, iris)

```

```{r }
summary(fit.MLR)


```

```{r }
probabilities.MLR <- predict(fit.MLR, iris[,1:4], type="response")
predictions <- apply(probabilities.MLR, 1, which.max)
predictions[which(predictions=="1")] <- levels(iris$Species)[1]
predictions[which(predictions=="2")] <- levels(iris$Species)[2]
predictions[which(predictions=="3")] <- levels(iris$Species)[3]

# Summarize accuracy
trn_tab <- table(iris$Species, predictions) 

```

#### Ipportamos libreria 'caret' para para obtener las metricas del modelo

```{r }

library("caret")
confusionMatrix(trn_tab, positive = "1")
```

#### Razon de Probabilidad

```{r }

exp(cbind(OR = coef(fit.MLR), confint(fit.MLR)))
```



